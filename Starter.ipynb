{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import *\n",
    "from evaluate_captions import *\n",
    "import csv\n",
    "from build_vocab import *\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from model import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.81s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 540/414113 [00:00<01:16, 5392.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:08<00:00, 6004.45it/s]\n"
     ]
    }
   ],
   "source": [
    "train_json = './data/annotations/captions_train2014.json'\n",
    "test_json = './data/annotations/captions_val2014.json'\n",
    "train_root = './data/images/train/'\n",
    "test_root = './data/images/test/'\n",
    "vocab = build_vocab(train_json)\n",
    "with open('TrainImageIds.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    trainIds = list(reader)\n",
    "trainIds = [int(i) for i in trainIds[0]]\n",
    "#train_dataset = CocoDataset(train_root, train_json, trainIds, vocab)\n",
    "\n",
    "valIds = trainIds[-len(trainIds)//5:]\n",
    "trainIds = trainIds[:-len(trainIds)//5]\n",
    "\n",
    "with open('TestImageIds.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    testIds = list(reader)\n",
    "testIds = [int(i) for i in testIds[0]]\n",
    "#test_dataset = CocoDataset(test_root, test_json, testIds, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.99s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.98s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "tsfm = transforms.Compose([\n",
    "        transforms.Resize(size=(300,300)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "train_loader = get_loader(train_root, train_json, trainIds, vocab, \n",
    "                          transform=tsfm, \n",
    "                          batch_size=50, \n",
    "                          shuffle=True, \n",
    "                          num_workers=4)\n",
    "val_loader = get_loader(train_root, train_json, valIds, vocab, \n",
    "                          transform=tsfm, \n",
    "                          batch_size=50, \n",
    "                          shuffle=True, \n",
    "                          num_workers=4)\n",
    "test_loader = get_loader(test_root, test_json, testIds, vocab, \n",
    "                          transform=tsfm, \n",
    "                          batch_size=10, \n",
    "                          shuffle=True, \n",
    "                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained word embedding\n",
    "#!curl  -L http://nlp.stanford.edu/data/glove.6B.zip>glove.6B.zip\n",
    "#!unzip glove.6B.zip\n",
    "pretrain_embed = False\n",
    "if pretrain_embed:\n",
    "    word2vec = {}\n",
    "    idx = 0\n",
    "    with open(\"glove.6B.300d.txt\",\"rb\") as f:\n",
    "        for l in tqdm(f.readlines()):\n",
    "            line = l.decode().split()\n",
    "            word2vec[line[0]] = [float(x) for x in line[1:]]\n",
    "            idx+=1\n",
    "    pretrained_weight = np.zeros((vocab.idx, 300))\n",
    "    for i in range(vocab.idx):\n",
    "        word = vocab[i]\n",
    "        if word in word2vec:\n",
    "            pretrained_weight[i] = word2vec[word]\n",
    "        else:\n",
    "            pretrained_weight[i] = np.random.randn(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 300\n",
    "vocab_size= vocab.idx\n",
    "hiddem_dim = 512\n",
    "\n",
    "\n",
    "baseline = Img_Caption(encoder= res50_encoder(embed_dim), rnn=nn.LSTM, \n",
    "                        vocab_size=vocab_size, \n",
    "                        embed_dim=embed_dim,\n",
    "                        hidden_dim=hiddem_dim,\n",
    "                        embed_weight = torch.tensor(pretrained_weight) if pretrain_embed else None\n",
    "                      )\n",
    "\n",
    "optimizer = optim.Adam(baseline.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    baseline = baseline.cuda()\n",
    "\n",
    "\n",
    "def train(mod, epochs):\n",
    "    mod.train()\n",
    "    best_loss = float('inf')\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        losss = []\n",
    "        ts = time.time()\n",
    "        for i, (imgs, caps, lengths) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                imgs = imgs.cuda()# Move your inputs onto the gpu\n",
    "                caps = caps.cuda()# Move your labels onto the gpu\n",
    "                #lengths = lengths.cuda()\n",
    "            \n",
    "            outputs = mod(imgs, caps, lengths)\n",
    "            targets = nn.utils.rnn.pack_padded_sequence(caps, lengths, batch_first=True)[0]\n",
    "            loss = criterion(outputs, targets)\n",
    "            losss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % 500 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, i, loss.item()))\n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        # torch.save(fcn_model, 'best_model')\n",
    "        \n",
    "        train_loss.append(np.mean(losss))\n",
    "        epoch_loss = val(mod)\n",
    "        val_loss.append(epoch_loss)\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(mod, 'best_model')\n",
    "        mod.train()\n",
    "    return train_loss,val_loss\n",
    "def val(mod):\n",
    "    mod.eval()\n",
    "    \n",
    "    ts = time.time()\n",
    "    val_loss = 0\n",
    "    for i, (imgs, caps, lengths) in enumerate(val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_gpu:\n",
    "            imgs = imgs.cuda()# Move your inputs onto the gpu\n",
    "            caps = caps.cuda()# Move your labels onto the gpu\n",
    "            #lengths = lengths.cuda()\n",
    "\n",
    "        outputs = mod(imgs, caps, lengths)\n",
    "        targets = nn.utils.rnn.pack_padded_sequence(caps, lengths, batch_first=True)[0]\n",
    "        loss = criterion(outputs, targets)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"iter{}, loss: {}\".format(i, loss.item()))\n",
    "    val_loss/=len(val_loader)\n",
    "    print('validation loss:', val_loss)\n",
    "    print(\"Finish validation time elapsed {}\".format(time.time() - ts))\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, iter0, loss: 10.130311965942383\n",
      "epoch0, iter100, loss: 4.014859676361084\n",
      "epoch0, iter200, loss: 3.560607671737671\n",
      "epoch0, iter300, loss: 3.490773916244507\n",
      "epoch0, iter400, loss: 3.408262014389038\n",
      "epoch0, iter500, loss: 3.325308084487915\n",
      "epoch0, iter600, loss: 3.2753801345825195\n",
      "epoch0, iter700, loss: 3.1713428497314453\n",
      "epoch0, iter800, loss: 2.9207377433776855\n",
      "epoch0, iter900, loss: 3.1874606609344482\n",
      "epoch0, iter1000, loss: 3.2764930725097656\n",
      "epoch0, iter1100, loss: 3.036099672317505\n",
      "epoch0, iter1200, loss: 2.9958560466766357\n",
      "epoch0, iter1300, loss: 2.9283697605133057\n",
      "Finish epoch 0, time elapsed 236.15938305854797\n",
      "iter0, loss: 3.0030698776245117\n",
      "iter100, loss: 3.080371379852295\n",
      "iter200, loss: 2.8455560207366943\n",
      "iter300, loss: 2.812453508377075\n",
      "validation loss: 2.916932142642607\n",
      "Finish validation time elapsed 61.047523498535156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Img_Caption. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Bottleneck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1, iter0, loss: 2.5475456714630127\n",
      "epoch1, iter100, loss: 2.7789053916931152\n",
      "epoch1, iter200, loss: 2.5495171546936035\n",
      "epoch1, iter300, loss: 2.764979124069214\n",
      "epoch1, iter400, loss: 2.873788833618164\n",
      "epoch1, iter500, loss: 2.5419955253601074\n",
      "epoch1, iter600, loss: 2.8555636405944824\n",
      "epoch1, iter700, loss: 2.7728629112243652\n",
      "epoch1, iter800, loss: 2.409437656402588\n",
      "epoch1, iter900, loss: 2.572618007659912\n",
      "epoch1, iter1000, loss: 2.8724899291992188\n",
      "epoch1, iter1100, loss: 2.7364134788513184\n",
      "epoch1, iter1200, loss: 2.8981401920318604\n",
      "epoch1, iter1300, loss: 2.653214454650879\n",
      "Finish epoch 1, time elapsed 241.2845757007599\n",
      "iter0, loss: 2.6104214191436768\n",
      "iter100, loss: 2.54329252243042\n",
      "iter200, loss: 2.6458828449249268\n",
      "iter300, loss: 2.8065383434295654\n",
      "validation loss: 2.6706660375537643\n",
      "Finish validation time elapsed 60.04452562332153\n",
      "epoch2, iter0, loss: 2.453793525695801\n",
      "epoch2, iter100, loss: 2.2764360904693604\n",
      "epoch2, iter200, loss: 2.485788106918335\n",
      "epoch2, iter300, loss: 2.5561468601226807\n",
      "epoch2, iter400, loss: 2.425610303878784\n",
      "epoch2, iter500, loss: 2.431976318359375\n",
      "epoch2, iter600, loss: 2.199276924133301\n",
      "epoch2, iter700, loss: 2.468043565750122\n",
      "epoch2, iter800, loss: 2.494574546813965\n",
      "epoch2, iter900, loss: 2.4722349643707275\n",
      "epoch2, iter1000, loss: 2.3286428451538086\n",
      "epoch2, iter1100, loss: 2.3579516410827637\n",
      "epoch2, iter1200, loss: 2.4501960277557373\n",
      "epoch2, iter1300, loss: 2.614503860473633\n",
      "Finish epoch 2, time elapsed 230.61411046981812\n",
      "iter0, loss: 3.0016326904296875\n",
      "iter100, loss: 2.595673084259033\n",
      "iter200, loss: 2.6692051887512207\n",
      "iter300, loss: 2.6255853176116943\n",
      "validation loss: 2.5690211172563484\n",
      "Finish validation time elapsed 63.41634392738342\n",
      "epoch3, iter0, loss: 2.421168088912964\n",
      "epoch3, iter100, loss: 2.2704150676727295\n",
      "epoch3, iter200, loss: 2.338101863861084\n",
      "epoch3, iter300, loss: 2.5041158199310303\n",
      "epoch3, iter400, loss: 2.180720329284668\n",
      "epoch3, iter500, loss: 2.3291003704071045\n",
      "epoch3, iter600, loss: 2.563005208969116\n",
      "epoch3, iter700, loss: 2.2846739292144775\n",
      "epoch3, iter800, loss: 2.743393659591675\n",
      "epoch3, iter900, loss: 2.422236204147339\n",
      "epoch3, iter1000, loss: 2.2565040588378906\n",
      "epoch3, iter1100, loss: 2.3781235218048096\n",
      "epoch3, iter1200, loss: 2.2513606548309326\n",
      "epoch3, iter1300, loss: 2.6228995323181152\n",
      "Finish epoch 3, time elapsed 249.2022829055786\n",
      "iter0, loss: 2.4775798320770264\n",
      "iter100, loss: 2.637634038925171\n",
      "iter200, loss: 2.430742025375366\n",
      "iter300, loss: 2.736138343811035\n",
      "validation loss: 2.512885762266366\n",
      "Finish validation time elapsed 63.03925561904907\n",
      "epoch4, iter0, loss: 2.0328409671783447\n",
      "epoch4, iter100, loss: 2.1891894340515137\n",
      "epoch4, iter200, loss: 2.3387742042541504\n",
      "epoch4, iter300, loss: 2.0303146839141846\n",
      "epoch4, iter400, loss: 2.3307299613952637\n",
      "epoch4, iter500, loss: 2.1170814037323\n",
      "epoch4, iter600, loss: 2.366121292114258\n",
      "epoch4, iter700, loss: 2.1834516525268555\n",
      "epoch4, iter800, loss: 2.2643542289733887\n",
      "epoch4, iter900, loss: 2.3988125324249268\n",
      "epoch4, iter1000, loss: 2.2598462104797363\n",
      "epoch4, iter1100, loss: 2.026311159133911\n",
      "epoch4, iter1200, loss: 2.2840206623077393\n",
      "epoch4, iter1300, loss: 2.432626724243164\n",
      "Finish epoch 4, time elapsed 238.701069355011\n",
      "iter0, loss: 2.4636588096618652\n",
      "iter100, loss: 2.6129062175750732\n",
      "iter200, loss: 2.273639440536499\n",
      "iter300, loss: 2.5657780170440674\n",
      "validation loss: 2.487906862454242\n",
      "Finish validation time elapsed 58.5298285484314\n",
      "epoch5, iter0, loss: 2.000302314758301\n",
      "epoch5, iter100, loss: 2.1320271492004395\n",
      "epoch5, iter200, loss: 2.372243642807007\n",
      "epoch5, iter300, loss: 2.0709187984466553\n",
      "epoch5, iter400, loss: 2.0580966472625732\n",
      "epoch5, iter500, loss: 2.2521462440490723\n",
      "epoch5, iter600, loss: 2.2078335285186768\n",
      "epoch5, iter700, loss: 2.013169288635254\n",
      "epoch5, iter800, loss: 1.9586446285247803\n",
      "epoch5, iter900, loss: 2.3360209465026855\n",
      "epoch5, iter1000, loss: 2.0893096923828125\n",
      "epoch5, iter1100, loss: 2.3375091552734375\n",
      "epoch5, iter1200, loss: 2.100198745727539\n",
      "epoch5, iter1300, loss: 2.378488779067993\n",
      "Finish epoch 5, time elapsed 249.8589632511139\n",
      "iter0, loss: 2.4618453979492188\n",
      "iter100, loss: 2.3796463012695312\n",
      "iter200, loss: 2.406151056289673\n",
      "iter300, loss: 2.5749142169952393\n",
      "validation loss: 2.459792963711612\n",
      "Finish validation time elapsed 64.25561928749084\n",
      "epoch6, iter0, loss: 2.06306529045105\n",
      "epoch6, iter100, loss: 2.150177001953125\n",
      "epoch6, iter200, loss: 1.772208333015442\n",
      "epoch6, iter300, loss: 2.2070465087890625\n",
      "epoch6, iter400, loss: 2.0317840576171875\n",
      "epoch6, iter500, loss: 1.93903648853302\n",
      "epoch6, iter600, loss: 2.1301281452178955\n",
      "epoch6, iter700, loss: 1.9819047451019287\n",
      "epoch6, iter800, loss: 2.2666680812835693\n",
      "epoch6, iter900, loss: 2.0548064708709717\n",
      "epoch6, iter1000, loss: 2.2677512168884277\n",
      "epoch6, iter1100, loss: 2.1130244731903076\n",
      "epoch6, iter1200, loss: 2.1645169258117676\n",
      "epoch6, iter1300, loss: 2.0943000316619873\n",
      "Finish epoch 6, time elapsed 255.9600510597229\n",
      "iter0, loss: 2.597632646560669\n",
      "iter100, loss: 2.486701250076294\n",
      "iter200, loss: 2.4169692993164062\n",
      "iter300, loss: 2.524507999420166\n",
      "validation loss: 2.454940593386271\n",
      "Finish validation time elapsed 67.37315559387207\n",
      "epoch7, iter0, loss: 1.9186784029006958\n",
      "epoch7, iter100, loss: 1.9480938911437988\n",
      "epoch7, iter200, loss: 1.832929015159607\n",
      "epoch7, iter300, loss: 2.040806293487549\n",
      "epoch7, iter400, loss: 2.2046871185302734\n",
      "epoch7, iter500, loss: 2.188326835632324\n",
      "epoch7, iter600, loss: 2.10624098777771\n",
      "epoch7, iter700, loss: 1.84647798538208\n",
      "epoch7, iter800, loss: 2.036774158477783\n",
      "epoch7, iter900, loss: 2.107194423675537\n",
      "epoch7, iter1000, loss: 1.8128105401992798\n",
      "epoch7, iter1100, loss: 2.0216050148010254\n",
      "epoch7, iter1200, loss: 2.050856113433838\n",
      "epoch7, iter1300, loss: 1.997138261795044\n",
      "Finish epoch 7, time elapsed 259.35055565834045\n",
      "iter0, loss: 2.338130235671997\n",
      "iter100, loss: 2.445721387863159\n",
      "iter200, loss: 2.2735366821289062\n",
      "iter300, loss: 2.687398910522461\n",
      "validation loss: 2.447825892143939\n",
      "Finish validation time elapsed 64.63061833381653\n",
      "epoch8, iter0, loss: 1.8014676570892334\n",
      "epoch8, iter100, loss: 1.8594653606414795\n",
      "epoch8, iter200, loss: 1.9539868831634521\n",
      "epoch8, iter300, loss: 1.9964361190795898\n",
      "epoch8, iter400, loss: 2.03007173538208\n",
      "epoch8, iter500, loss: 1.9539908170700073\n",
      "epoch8, iter600, loss: 1.9116629362106323\n",
      "epoch8, iter700, loss: 1.9964100122451782\n",
      "epoch8, iter800, loss: 2.0336191654205322\n",
      "epoch8, iter900, loss: 1.9411259889602661\n",
      "epoch8, iter1000, loss: 2.0594711303710938\n",
      "epoch8, iter1100, loss: 2.1345925331115723\n",
      "epoch8, iter1200, loss: 2.0559191703796387\n",
      "epoch8, iter1300, loss: 2.0914056301116943\n",
      "Finish epoch 8, time elapsed 261.50991582870483\n",
      "iter0, loss: 2.408395767211914\n",
      "iter100, loss: 2.499955177307129\n",
      "iter200, loss: 2.366905689239502\n",
      "iter300, loss: 2.5085980892181396\n",
      "validation loss: 2.447529024388417\n",
      "Finish validation time elapsed 65.231862783432\n",
      "epoch9, iter0, loss: 1.814573884010315\n",
      "epoch9, iter100, loss: 1.6780422925949097\n",
      "epoch9, iter200, loss: 2.043987274169922\n",
      "epoch9, iter300, loss: 1.8851902484893799\n",
      "epoch9, iter400, loss: 1.9554606676101685\n",
      "epoch9, iter500, loss: 2.0986602306365967\n",
      "epoch9, iter600, loss: 1.8676882982254028\n",
      "epoch9, iter700, loss: 1.899964451789856\n",
      "epoch9, iter800, loss: 1.9555388689041138\n",
      "epoch9, iter900, loss: 2.0281529426574707\n",
      "epoch9, iter1000, loss: 2.0775580406188965\n",
      "epoch9, iter1100, loss: 1.805876612663269\n",
      "epoch9, iter1200, loss: 2.002701997756958\n",
      "epoch9, iter1300, loss: 1.883639931678772\n",
      "Finish epoch 9, time elapsed 259.32451486587524\n",
      "iter0, loss: 2.3683836460113525\n",
      "iter100, loss: 2.402189254760742\n",
      "iter200, loss: 2.47499418258667\n",
      "iter300, loss: 2.721895456314087\n",
      "validation loss: 2.444543541195881\n",
      "Finish validation time elapsed 65.86049318313599\n",
      "epoch10, iter0, loss: 1.8901485204696655\n",
      "epoch10, iter100, loss: 1.8031740188598633\n",
      "epoch10, iter200, loss: 1.8426356315612793\n",
      "epoch10, iter300, loss: 1.9969671964645386\n",
      "epoch10, iter400, loss: 1.8982352018356323\n",
      "epoch10, iter500, loss: 2.018139123916626\n",
      "epoch10, iter600, loss: 1.7822504043579102\n",
      "epoch10, iter700, loss: 1.9992146492004395\n",
      "epoch10, iter800, loss: 2.1188669204711914\n",
      "epoch10, iter900, loss: 1.9406821727752686\n",
      "epoch10, iter1000, loss: 2.0627267360687256\n",
      "epoch10, iter1100, loss: 2.1573374271392822\n",
      "epoch10, iter1200, loss: 1.9780234098434448\n",
      "epoch10, iter1300, loss: 2.028329372406006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 10, time elapsed 256.98368859291077\n",
      "iter0, loss: 2.50836443901062\n",
      "iter100, loss: 2.2728538513183594\n",
      "iter200, loss: 2.310086727142334\n",
      "iter300, loss: 2.473691701889038\n",
      "validation loss: 2.4498613419302977\n",
      "Finish validation time elapsed 66.97195529937744\n",
      "epoch11, iter0, loss: 1.8036317825317383\n",
      "epoch11, iter100, loss: 1.7329550981521606\n",
      "epoch11, iter200, loss: 1.8780702352523804\n",
      "epoch11, iter300, loss: 1.8397103548049927\n",
      "epoch11, iter400, loss: 1.8848369121551514\n",
      "epoch11, iter500, loss: 2.0606188774108887\n",
      "epoch11, iter600, loss: 1.861642837524414\n",
      "epoch11, iter700, loss: 1.9104866981506348\n",
      "epoch11, iter800, loss: 1.8545385599136353\n",
      "epoch11, iter900, loss: 1.8147387504577637\n",
      "epoch11, iter1000, loss: 1.7914109230041504\n",
      "epoch11, iter1100, loss: 1.926758885383606\n",
      "epoch11, iter1200, loss: 1.772322654724121\n",
      "epoch11, iter1300, loss: 1.9191911220550537\n",
      "Finish epoch 11, time elapsed 254.34884572029114\n",
      "iter0, loss: 2.517897605895996\n",
      "iter100, loss: 2.373229503631592\n",
      "iter200, loss: 2.4644644260406494\n",
      "iter300, loss: 2.4773151874542236\n",
      "validation loss: 2.459660805133452\n",
      "Finish validation time elapsed 64.16149973869324\n",
      "epoch12, iter0, loss: 1.7934242486953735\n",
      "epoch12, iter100, loss: 1.7872861623764038\n",
      "epoch12, iter200, loss: 1.882843255996704\n",
      "epoch12, iter300, loss: 1.822412371635437\n",
      "epoch12, iter400, loss: 1.8974016904830933\n",
      "epoch12, iter500, loss: 1.7774738073349\n",
      "epoch12, iter600, loss: 1.6476287841796875\n",
      "epoch12, iter700, loss: 1.8955678939819336\n",
      "epoch12, iter800, loss: 1.880000114440918\n",
      "epoch12, iter900, loss: 1.794634461402893\n",
      "epoch12, iter1000, loss: 1.895696997642517\n",
      "epoch12, iter1100, loss: 1.6536893844604492\n",
      "epoch12, iter1200, loss: 1.7789216041564941\n",
      "epoch12, iter1300, loss: 2.005046844482422\n",
      "Finish epoch 12, time elapsed 249.25579643249512\n",
      "iter0, loss: 2.2767884731292725\n",
      "iter100, loss: 2.4621989727020264\n",
      "iter200, loss: 2.3991472721099854\n",
      "iter300, loss: 2.325631618499756\n",
      "validation loss: 2.4628639903413245\n",
      "Finish validation time elapsed 63.35472846031189\n",
      "epoch13, iter0, loss: 1.711573600769043\n",
      "epoch13, iter100, loss: 1.7757997512817383\n",
      "epoch13, iter200, loss: 1.8614685535430908\n",
      "epoch13, iter300, loss: 1.733998417854309\n",
      "epoch13, iter400, loss: 1.8153074979782104\n",
      "epoch13, iter500, loss: 1.7293665409088135\n",
      "epoch13, iter600, loss: 1.8651800155639648\n",
      "epoch13, iter700, loss: 1.7802841663360596\n",
      "epoch13, iter800, loss: 1.8400050401687622\n",
      "epoch13, iter900, loss: 1.818010926246643\n",
      "epoch13, iter1000, loss: 1.9667845964431763\n",
      "epoch13, iter1100, loss: 1.912729024887085\n",
      "epoch13, iter1200, loss: 1.939171314239502\n",
      "epoch13, iter1300, loss: 1.8506940603256226\n",
      "Finish epoch 13, time elapsed 246.08801078796387\n",
      "iter0, loss: 2.6490349769592285\n",
      "iter100, loss: 2.7149200439453125\n",
      "iter200, loss: 2.6027400493621826\n",
      "iter300, loss: 2.353196620941162\n",
      "validation loss: 2.4662990017109605\n",
      "Finish validation time elapsed 62.04653716087341\n",
      "epoch14, iter0, loss: 1.58430016040802\n",
      "epoch14, iter100, loss: 1.7389074563980103\n",
      "epoch14, iter200, loss: 1.5869591236114502\n",
      "epoch14, iter300, loss: 1.8377772569656372\n",
      "epoch14, iter400, loss: 1.6415464878082275\n",
      "epoch14, iter500, loss: 1.8435180187225342\n",
      "epoch14, iter600, loss: 1.646837830543518\n",
      "epoch14, iter700, loss: 1.7718697786331177\n",
      "epoch14, iter800, loss: 1.9051485061645508\n",
      "epoch14, iter900, loss: 1.8217264413833618\n",
      "epoch14, iter1000, loss: 1.9626524448394775\n",
      "epoch14, iter1100, loss: 2.0161616802215576\n",
      "epoch14, iter1200, loss: 1.781990647315979\n",
      "epoch14, iter1300, loss: 2.0314230918884277\n",
      "Finish epoch 14, time elapsed 248.96492671966553\n",
      "iter0, loss: 2.6266210079193115\n",
      "iter100, loss: 2.9006614685058594\n",
      "iter200, loss: 2.678558349609375\n",
      "iter300, loss: 2.6241917610168457\n",
      "validation loss: 2.4757287035505455\n",
      "Finish validation time elapsed 61.51449632644653\n",
      "epoch15, iter0, loss: 1.7546930313110352\n",
      "epoch15, iter100, loss: 1.7629321813583374\n",
      "epoch15, iter200, loss: 1.8618535995483398\n",
      "epoch15, iter300, loss: 1.9116697311401367\n",
      "epoch15, iter400, loss: 1.781792163848877\n",
      "epoch15, iter500, loss: 1.6347483396530151\n",
      "epoch15, iter600, loss: 1.5990773439407349\n",
      "epoch15, iter700, loss: 1.6214745044708252\n",
      "epoch15, iter800, loss: 1.897365689277649\n",
      "epoch15, iter900, loss: 2.055171489715576\n",
      "epoch15, iter1000, loss: 1.7613894939422607\n",
      "epoch15, iter1100, loss: 1.8135950565338135\n",
      "epoch15, iter1200, loss: 1.946244239807129\n",
      "epoch15, iter1300, loss: 1.9333231449127197\n",
      "Finish epoch 15, time elapsed 251.99842381477356\n",
      "iter0, loss: 2.2698323726654053\n",
      "iter100, loss: 2.3800320625305176\n",
      "iter200, loss: 2.4205617904663086\n",
      "iter300, loss: 2.2698328495025635\n",
      "validation loss: 2.484542890485511\n",
      "Finish validation time elapsed 62.67597675323486\n",
      "epoch16, iter0, loss: 1.6731557846069336\n",
      "epoch16, iter100, loss: 1.7184914350509644\n",
      "epoch16, iter200, loss: 1.7296497821807861\n",
      "epoch16, iter300, loss: 1.518800973892212\n",
      "epoch16, iter400, loss: 1.7167205810546875\n",
      "epoch16, iter500, loss: 1.7379814386367798\n",
      "epoch16, iter600, loss: 1.7668817043304443\n",
      "epoch16, iter700, loss: 1.8474819660186768\n",
      "epoch16, iter800, loss: 1.7253122329711914\n",
      "epoch16, iter900, loss: 1.7987914085388184\n",
      "epoch16, iter1000, loss: 1.8422610759735107\n",
      "epoch16, iter1100, loss: 1.8833783864974976\n",
      "epoch16, iter1200, loss: 1.8974851369857788\n",
      "epoch16, iter1300, loss: 1.6249427795410156\n",
      "Finish epoch 16, time elapsed 245.88103914260864\n",
      "iter0, loss: 2.2982349395751953\n",
      "iter100, loss: 2.514951229095459\n",
      "iter200, loss: 2.488579034805298\n",
      "iter300, loss: 2.6164350509643555\n",
      "validation loss: 2.49811504332416\n",
      "Finish validation time elapsed 64.9358594417572\n",
      "epoch17, iter0, loss: 1.48848295211792\n",
      "epoch17, iter100, loss: 1.6622942686080933\n",
      "epoch17, iter200, loss: 1.6426026821136475\n",
      "epoch17, iter300, loss: 1.514925479888916\n",
      "epoch17, iter400, loss: 1.6705553531646729\n",
      "epoch17, iter500, loss: 1.8216681480407715\n",
      "epoch17, iter600, loss: 1.7044129371643066\n",
      "epoch17, iter700, loss: 1.6899971961975098\n",
      "epoch17, iter800, loss: 1.735252022743225\n",
      "epoch17, iter900, loss: 1.737913727760315\n",
      "epoch17, iter1000, loss: 1.7051252126693726\n",
      "epoch17, iter1100, loss: 1.7592065334320068\n",
      "epoch17, iter1200, loss: 1.613516092300415\n",
      "epoch17, iter1300, loss: 1.7118979692459106\n",
      "Finish epoch 17, time elapsed 238.32822132110596\n",
      "iter0, loss: 2.639946937561035\n",
      "iter100, loss: 2.5209543704986572\n",
      "iter200, loss: 2.7524938583374023\n",
      "iter300, loss: 2.332873821258545\n",
      "validation loss: 2.504976287663701\n",
      "Finish validation time elapsed 62.33542513847351\n",
      "epoch18, iter0, loss: 1.533958077430725\n",
      "epoch18, iter100, loss: 1.5318235158920288\n",
      "epoch18, iter200, loss: 1.5190752744674683\n",
      "epoch18, iter300, loss: 1.6463477611541748\n",
      "epoch18, iter400, loss: 1.5810412168502808\n",
      "epoch18, iter500, loss: 1.6332157850265503\n",
      "epoch18, iter600, loss: 1.5992833375930786\n",
      "epoch18, iter700, loss: 1.7153775691986084\n",
      "epoch18, iter800, loss: 1.6355044841766357\n",
      "epoch18, iter900, loss: 1.734039068222046\n",
      "epoch18, iter1000, loss: 1.7429728507995605\n",
      "epoch18, iter1100, loss: 1.9639915227890015\n",
      "epoch18, iter1200, loss: 1.6810320615768433\n",
      "epoch18, iter1300, loss: 1.8642629384994507\n",
      "Finish epoch 18, time elapsed 236.01805210113525\n",
      "iter0, loss: 2.2815096378326416\n",
      "iter100, loss: 2.4951095581054688\n",
      "iter200, loss: 2.635875701904297\n",
      "iter300, loss: 2.4367120265960693\n",
      "validation loss: 2.5187452615025534\n",
      "Finish validation time elapsed 61.60108542442322\n",
      "epoch19, iter0, loss: 1.526608943939209\n",
      "epoch19, iter100, loss: 1.6253516674041748\n",
      "epoch19, iter200, loss: 1.572853922843933\n",
      "epoch19, iter300, loss: 1.7120050191879272\n",
      "epoch19, iter400, loss: 1.6378908157348633\n",
      "epoch19, iter500, loss: 1.6356685161590576\n",
      "epoch19, iter600, loss: 1.6441147327423096\n",
      "epoch19, iter700, loss: 1.635616421699524\n",
      "epoch19, iter800, loss: 1.5865507125854492\n",
      "epoch19, iter900, loss: 1.5766043663024902\n",
      "epoch19, iter1000, loss: 1.4629883766174316\n",
      "epoch19, iter1100, loss: 1.745248556137085\n",
      "epoch19, iter1200, loss: 1.7540873289108276\n",
      "epoch19, iter1300, loss: 1.901900053024292\n",
      "Finish epoch 19, time elapsed 259.2379128932953\n",
      "iter0, loss: 2.5219759941101074\n",
      "iter100, loss: 2.4413678646087646\n",
      "iter200, loss: 2.368868827819824\n",
      "iter300, loss: 2.6680240631103516\n",
      "validation loss: 2.529461444142353\n",
      "Finish validation time elapsed 67.75315594673157\n"
     ]
    }
   ],
   "source": [
    "epochs  = 20\n",
    "train_loss, val_loss = train(baseline, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxtowords(idxs):\n",
    "    words = []\n",
    "    for idx in idxs:\n",
    "        if idx == 3:\n",
    "            break\n",
    "        words.append(vocab[idx])\n",
    "    return \" \".join(words)\n",
    "def test(mod):\n",
    "    mod.eval()\n",
    "    for i, (imgs, caps, lengths) in enumerate(test_loader):\n",
    "    \n",
    "        if use_gpu:\n",
    "            imgs = imgs.cuda()# Move your inputs onto the gpu\n",
    "            caps = caps.cuda()# Move your labels onto the gpu\n",
    "            #lengths = lengths.cuda()\n",
    "            \n",
    "        feature = mod.encoder(imgs)\n",
    "        sampled_ids = mod.sample(feature,max_length = 20)\n",
    "        \n",
    "         \n",
    "#         sampled_ids = sampled_ids[0].cpu().numpy()\n",
    "        \n",
    "#         sampled_caption = []\n",
    "        \n",
    "#         for word_id in sampled_ids:\n",
    "#             word = vocab.idx2word[word_id]\n",
    "#             sampled_caption.append(word)\n",
    "#             if word == '<end>':\n",
    "#                 break\n",
    "                \n",
    "#         sentence = ' '.join(sampled_caption)\n",
    "#         print (sentence)\n",
    "        \n",
    "#         sampled_caption = []\n",
    "        \n",
    "#         for word_id in caps[0].cpu().numpy():\n",
    "#             word = vocab.idx2word[word_id]\n",
    "#             sampled_caption.append(word)\n",
    "#             if word == '<end>':\n",
    "#                 break\n",
    "#         sentence = ' '.join(sampled_caption)\n",
    "#         print(sentence)\n",
    "#         plt.imshow(np.asarray(imgs[0].cpu().permute(1,2,0)))\n",
    "        capfile = open('caption.txt', 'a')\n",
    "        genfile = open('generation.txt', 'a')\n",
    "        sampled_ids = sampled_ids.cpu().numpy()\n",
    "        caps = caps.cpu().numpy()\n",
    "        for i in range(len(caps)):\n",
    "            capfile.write(idxtowords(caps[i])+'\\n')\n",
    "            genfile.write(idxtowords(sampled_ids[i])+'\\n')\n",
    "        capfile.close()\n",
    "        genfile.close()\n",
    "#         imgs = np.asarray(imgs.cpu().permute(0,2,3,1))\n",
    "#         for i in range(10):\n",
    "#             generate = idxtowords(sampled_ids[i])\n",
    "#             label = idxtowords(caps[i])\n",
    "#             print('label:',label)\n",
    "#             print('generate:',generate)\n",
    "#             img = imgs[i]\n",
    "#             img-=np.min(img)\n",
    "#             img/=np.max(img)\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "#         break\n",
    "        \n",
    "def test_stochastic(mod,temp):\n",
    "    mod.eval()\n",
    "    for i, (imgs, caps, lengths) in enumerate(test_loader):\n",
    "    \n",
    "        if use_gpu:\n",
    "            imgs = imgs.cuda()# Move your inputs onto the gpu\n",
    "            caps = caps.cuda()# Move your labels onto the gpu\n",
    "            #lengths = lengths.cuda()\n",
    "            \n",
    "        feature = mod.encoder(imgs)\n",
    "        sampled_ids = mod.Stochastic_sample(feature,max_length = 20,temp = temp)\n",
    "        capfile = open('caption.txt', 'a')\n",
    "        genfile = open('generation.txt', 'a')\n",
    "        sampled_ids = sampled_ids.cpu().numpy()\n",
    "        caps = caps.cpu().numpy()\n",
    "        for i in range(len(caps)):\n",
    "            capfile.write(idxtowords(caps[i])+'\\n')\n",
    "            genfile.write(idxtowords(sampled_ids[i])+'\\n')\n",
    "        capfile.close()\n",
    "        genfile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = torch.load(\"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Img_Caption(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=300, bias=True)\n",
       "  )\n",
       "  (embed): Embedding(25123, 300)\n",
       "  (rnn): LSTM(300, 512, batch_first=True)\n",
       "  (output): Linear(in_features=512, out_features=25123, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = torch.load('best_model')\n",
    "mod.cuda()\n",
    "#test(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stochastic(mod,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15011it [04:32, 58.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU 1: 33.31 BLEU 4: 0.2\n",
      "33.30623554779772 0.19615396484316874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test_stochastic(mod,0.1)\n",
    "BLEU_1 , BLEU_4  = evaluate_captions('caption.txt',\"generation.txt\")\n",
    "print(BLEU_1,BLEU_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM no pretrain embedding\n",
    "Deterministic  BLEU_1 :   33.27         BLEU_4:  0.2\n",
    "temp = 0.1     BLEU_1 :   33.31         BLEU_4:  0.196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epoch = np.arange(0,20)\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(epoch,train_loss,label = \"Train loss\")\n",
    "plt.plot(epoch,val_loss,label = \"Validation loss\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"log.txt\", \"w\")\n",
    "fo.write(str(train_loss))\n",
    "fo.write(\"\\n\")\n",
    "fo.write(str(val_loss))\n",
    "\n",
    "fo.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
